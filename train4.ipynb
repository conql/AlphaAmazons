{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from model import NeuralNet\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from pprint import pprint\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatchDataSet(Dataset):\n",
    "    def __init__(self, data: dict):\n",
    "        self.data = data\n",
    "        self.keys = list(data.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        board = torch.tensor(self.data[self.keys[index]][0], dtype=torch.int8)\n",
    "        answer = torch.tensor(self.data[self.keys[index]][1], dtype=torch.int8)\n",
    "        return (board, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    input = []\n",
    "    policies = []\n",
    "    values = []\n",
    "    for i, (board, answer, value) in enumerate(batch):\n",
    "        player = board[answer[1]][answer[0]]\n",
    "        if player != 1 and player != 2:\n",
    "            raise Exception(\"Invalid player: {}\".format(player))\n",
    "\n",
    "        # pprint(board)\n",
    "        # pprint(answer)\n",
    "\n",
    "        input.append(NeuralNet.process_input(board, player, 0))\n",
    "        input.append(NeuralNet.process_input(board, player, 1, answer[0], answer[1]))\n",
    "\n",
    "        n_board = board.clone()\n",
    "        n_board[answer[1], answer[0]] = 0\n",
    "        n_board[answer[3], answer[2]] = player\n",
    "\n",
    "        input.append(NeuralNet.process_input(n_board, player, 2, answer[2], answer[3]))\n",
    "\n",
    "        p1, v1 = NeuralNet.process_output(value, answer[0], answer[1], board, player, 0)\n",
    "\n",
    "        p2, v2 = NeuralNet.process_output(value, answer[2], answer[3], board, player, 1, answer[0], answer[1])\n",
    "\n",
    "        p3, v3 = NeuralNet.process_output(\n",
    "            value,\n",
    "            answer[4],\n",
    "            answer[5],\n",
    "            n_board,\n",
    "            player,\n",
    "            2,\n",
    "            answer[2],\n",
    "            answer[3],\n",
    "        )\n",
    "\n",
    "        policies.append(p1)\n",
    "        policies.append(p2)\n",
    "        policies.append(p3)\n",
    "\n",
    "        values.append(v1)\n",
    "        values.append(v2)\n",
    "        values.append(v3)\n",
    "\n",
    "    # convert to torch tensor\n",
    "    input = torch.stack(input)\n",
    "    policies = torch.stack(policies)\n",
    "    values = torch.stack(values)\n",
    "    return input, (policies, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    input_paths = glob(path, recursive=False)\n",
    "\n",
    "    data = {}\n",
    "    for path in tqdm(input_paths, desc=\"Loading data\", unit=\"file\"):\n",
    "        data = {**data, **pickle.load(open(path, \"rb\"))}\n",
    "\n",
    "    return MatchDataSet(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\huang\\.pyenv\\pyenv-win\\versions\\3.11.2\\Lib\\site-packages\\neptune\\common\\warnings.py:62: NeptuneWarning: To avoid unintended consumption of logging hours during interactive sessions, the following monitoring options are disabled unless set to 'True' when initializing the run: 'capture_stdout', 'capture_stderr', and 'capture_hardware_metrics'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/conql/Amazons/e/AM-76\n"
     ]
    }
   ],
   "source": [
    "model_name = \"data/resnet_01_40x128.pt\"\n",
    "data_path = \"data/augment/train/*.pickle\"\n",
    "\n",
    "config.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 100%|██████████| 181/181 [00:19<00:00,  9.18file/s]\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "train_dataset = load_dataset(data_path)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=config.batch_size, shuffle=True, collate_fn=collate_fn, num_workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "net = NeuralNet()\n",
    "if os.path.exists(model_name):\n",
    "    net.load(path=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "optimizer = torch.optim.Adam(net.model.parameters(), lr=config.lr)\n",
    "loss_pi = nn.CrossEntropyLoss()\n",
    "loss_v = nn.MSELoss()\n",
    "net.model.train()\n",
    "\n",
    "for epoch in range(config.epochs):\n",
    "    train_correct = 0\n",
    "    train_actual_correct = 0\n",
    "    train_ploss_sum = 0\n",
    "    train_vloss_sum = 0\n",
    "    train_count = 0\n",
    "\n",
    "    for i, (X, Y) in tqdm(\n",
    "        enumerate(train_loader), total=len(train_loader), desc=\"Training model\"\n",
    "    ):\n",
    "        input_data = X\n",
    "        target_pi, target_vs = Y\n",
    "        sample_size = input_data.shape[0]\n",
    "\n",
    "        if config.use_gpu:\n",
    "            input_data, target_pi, target_vs = (\n",
    "                input_data.contiguous().cuda(),\n",
    "                target_pi.contiguous().cuda(),\n",
    "                target_vs.contiguous().cuda(),\n",
    "            )\n",
    "\n",
    "        # predict\n",
    "        out_pi, out_v = net.model(input_data)\n",
    "\n",
    "        # Some samples have no value, so we need to replace it with the predicted value\n",
    "        target_vs[target_vs == 0] = out_v[target_vs == 0]\n",
    "\n",
    "        p_loss = loss_pi(out_pi, target_pi)\n",
    "        v_loss = loss_v(out_v, target_vs)\n",
    "\n",
    "        total_loss = p_loss + v_loss\n",
    "\n",
    "        # update loss\n",
    "        train_ploss_sum += p_loss.item() * sample_size\n",
    "        train_vloss_sum += v_loss.item() * sample_size\n",
    "\n",
    "        corrects = out_pi.view(sample_size, -1).argmax(1) == target_pi.view(\n",
    "            sample_size, -1\n",
    "        ).argmax(1)\n",
    "\n",
    "        # update correct\n",
    "        train_correct += corrects.sum().item()\n",
    "\n",
    "        # calculate actual correct: 3 consecutive corrects\n",
    "        ac = 0\n",
    "        for j in range(0, sample_size, 3):\n",
    "            if corrects[j] and corrects[j + 1] and corrects[j + 2]:\n",
    "                ac += 1\n",
    "        train_actual_correct += ac\n",
    "\n",
    "        train_count += sample_size\n",
    "\n",
    "        # backprop\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # update log\n",
    "        if i % 10 == 0:\n",
    "            config.run[\"policy loss\"].append(train_ploss_sum / train_count)\n",
    "            config.run[\"value loss\"].append(train_vloss_sum / train_count)\n",
    "            config.run[\"accuracy\"].append(train_correct / train_count)\n",
    "            config.run[\"actual accuracy\"].append(\n",
    "                train_actual_correct / (train_count / 3)\n",
    "            )\n",
    "\n",
    "            train_ploss_sum = 0\n",
    "            train_vloss_sum = 0\n",
    "            train_correct = 0\n",
    "            train_actual_correct = 0\n",
    "            train_count = 0\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            net.save(model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
